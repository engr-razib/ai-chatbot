<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <title>HuggingFace.js Chatbot</title>
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <style>
        :root {
            font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif;
        }

        body {
            margin: 0;
            background: #0b1220;
            color: #e6ecff;
            display: flex;
            height: 100vh;
        }

        .app {
            margin: auto;
            width: min(900px, 100%);
            height: min(720px, 100%);
            display: grid;
            grid-template-rows: auto 1fr auto;
            gap: 12px;
            padding: 16px;
        }

        .card {
            background: #111a2e;
            border: 1px solid #223;
            border-radius: 16px;
            box-shadow: 0 8px 30px rgba(0, 0, 0, .35);
        }

        .head {
            padding: 16px 18px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: #6aa6ff;
            box-shadow: 0 0 12px #6aa6ff;
        }

        .title {
            font-weight: 700;
            letter-spacing: .2px
        }

        #chat {
            overflow: auto;
            padding: 18px;
            display: flex;
            flex-direction: column;
            gap: 14px;
        }

        .msg {
            max-width: 75%;
            padding: 12px 14px;
            line-height: 1.45;
            border-radius: 14px;
            white-space: pre-wrap;
        }

        .user {
            align-self: flex-end;
            background: #27406b;
            border: 1px solid #3c5784;
        }

        .bot {
            align-self: flex-start;
            background: #19243b;
            border: 1px solid #2a3a5a;
        }

        .row {
            display: flex;
            gap: 10px;
            padding: 12px;
        }

        #input {
            flex: 1;
            padding: 12px 14px;
            border-radius: 12px;
            border: 1px solid #314567;
            background: #0e172b;
            color: #e6ecff;
        }

        button {
            padding: 12px 16px;
            border-radius: 12px;
            border: 1px solid #3c5784;
            background: #27406b;
            color: #e6ecff;
            cursor: pointer;
        }

        button:disabled {
            opacity: .5;
            cursor: not-allowed;
        }

        .model {
            font-size: .9rem;
            opacity: .8
        }

        .foot {
            padding: 8px 14px;
            font-size: .85rem;
            opacity: .7
        }

        a {
            color: #99c1ff
        }
    </style>
</head>

<body>
    <div class="app">
        <div class="card head">
            <div class="dot"></div>
            <div>
                <div class="title">HuggingFace.js Chatbot</div>
                <div class="model">Model: <span id="model-name">mistralai/Mistral-7B-Instruct-v0.3</span></div>
            </div>
        </div>

        <div id="chat" class="card" aria-live="polite"></div>

        <div class="card">
            <div class="row">
                <input id="input" placeholder="Type your message…" />
                <button id="send">Send</button>
            </div>
        </div>

        <div class="foot">
            Built with <code>@huggingface/inference</code> chat completion streaming. For production, hide your token
            behind a proxy.
        </div>
    </div>

    <script type="module">
        // Import the official Hugging Face Inference client (browser-compatible)
        import { InferenceClient } from "https://esm.sh/@huggingface/inference";

        // 1) Put your HF access token here (create one at https://huggingface.co/settings/tokens)
        // NOTE: Exposed in browser — keep local. Use the proxy option below for anything public.
        const HF_TOKEN = "huggingface token";

        // 2) Pick a chat-capable model available via HF Inference Providers.
        //    Good defaults: "mistralai/Mistral-7B-Instruct-v0.3", "HuggingFaceH4/zephyr-7b-beta"
        const MODEL = "mistralai/Mistral-7B-Instruct-v0.3";

        // Optionally you can force a provider, but "auto" works well.
        // See provider list & usage in docs. 
        // const PROVIDER = "hf-inference";

        const hf = new InferenceClient(HF_TOKEN);

        const chatEl = document.getElementById("chat");
        const inputEl = document.getElementById("input");
        const sendBtn = document.getElementById("send");
        document.getElementById("model-name").textContent = MODEL;

        const messages = []; // { role: "user" | "assistant", content: string }

        function addMessage(role, content) {
            const div = document.createElement("div");
            div.className = `msg ${role === "user" ? "user" : "bot"}`;
            div.textContent = content;
            chatEl.appendChild(div);
            chatEl.scrollTop = chatEl.scrollHeight;
            return div;
        }

        async function sendMessage() {
            const text = inputEl.value.trim();
            if (!text) return;
            inputEl.value = "";
            inputEl.focus();

            messages.push({ role: "user", content: text });
            addMessage("user", text);

            sendBtn.disabled = true;
            const botBubble = addMessage("assistant", ""); // we'll stream into this

            try {
                // Stream tokens as they arrive (Chat Completions)
                let assembled = "";
                for await (const chunk of hf.chatCompletionStream({
                    model: MODEL,
                    // provider: PROVIDER,  // uncomment to pin a provider
                    messages,
                    // generation params (tweak to taste)
                    max_tokens: 512,
                    temperature: 0.7,
                    top_p: 0.95,
                })) {
                    // The API yields OpenAI-style chunks; append deltas as they come
                    const choice = chunk?.choices?.[0];
                    const delta = choice?.delta?.content ?? "";
                    if (delta) {
                        assembled += delta;
                        botBubble.textContent = assembled;
                        chatEl.scrollTop = chatEl.scrollHeight;
                    }
                }

                // Persist assistant message in the transcript
                messages.push({ role: "assistant", content: botBubble.textContent });
            } catch (err) {
                botBubble.textContent = `⚠️ ${err?.message || err}`;
            } finally {
                sendBtn.disabled = false;
            }
        }

        sendBtn.addEventListener("click", sendMessage);
        inputEl.addEventListener("keydown", (e) => {
            if (e.key === "Enter" && !e.shiftKey) {
                e.preventDefault();
                sendMessage();
            }
        });
    </script>
</body>

</html>